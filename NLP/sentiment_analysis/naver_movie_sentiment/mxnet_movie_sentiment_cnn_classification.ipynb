{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chee/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from mxnet import gluon, init, nd\n",
    "from mxnet.contrib import text\n",
    "from mxnet.gluon import loss as gloss, nn\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr1d(X, K):\n",
    "    w = K.shape[0]\n",
    "    Y = nd.zeros((X.shape[0] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        Y[i] = (X[i: i + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[ 2.  5.  8. 11. 14. 17.]\n",
       "<NDArray 6 @cpu(0)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, K = nd.array([0, 1, 2, 3, 4, 5, 6]), nd.array([1, 2])\n",
    "corr1d(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr1d_multi_in(X, K):\n",
    "    # First, we traverse along the 0th dimension (channel dimension) of X and\n",
    "    # K. Then, we add them together by using * to turn the result list into a\n",
    "    # positional argument of the add_n function\n",
    "    return nd.add_n(*[corr1d(x, k) for x, k in zip(X, K)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[ 2.  8. 14. 20. 26. 32.]\n",
       "<NDArray 6 @cpu(0)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = nd.array([[0, 1, 2, 3, 4, 5, 6],\n",
    "              [1, 2, 3, 4, 5, 6, 7],\n",
    "              [2, 3, 4, 5, 6, 7, 8]])\n",
    "K = nd.array([[1, 2], [3, 4], [-1, -3]])\n",
    "corr1d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Block):\n",
    "    def __init__(self, vocab_size, embed_size, kernel_sizes, num_channels,\n",
    "                 **kwargs):\n",
    "        super(TextCNN, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        # The embedding layer does not participate in training\n",
    "        self.constant_embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.decoder = nn.Dense(2)\n",
    "        # The max-over-time pooling layer has no weight, so it can share an\n",
    "        # instance\n",
    "        self.pool = nn.GlobalMaxPool1D()\n",
    "        # Create multiple one-dimensional convolutional layers\n",
    "        self.convs = nn.Sequential()\n",
    "        for c, k in zip(num_channels, kernel_sizes):\n",
    "            self.convs.add(nn.Conv1D(c, k, activation='relu'))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Concatenate the output of two embedding layers with shape of\n",
    "        # (batch size, number of words, word vector dimension) by word vector\n",
    "        embeddings = nd.concat(\n",
    "            self.embedding(inputs), self.constant_embedding(inputs), dim=2)\n",
    "        # According to the input format required by Conv1D, the word vector\n",
    "        # dimension, that is, the channel dimension of the one-dimensional\n",
    "        # convolutional layer, is transformed into the previous dimension\n",
    "        embeddings = embeddings.transpose((0, 2, 1))\n",
    "        # For each one-dimensional convolutional layer, after max-over-time\n",
    "        # pooling, an NDArray with the shape of (batch size, channel size, 1)\n",
    "        # can be obtained. Use the flatten function to remove the last\n",
    "        # dimension and then concatenate on the channel dimension\n",
    "        encoding = nd.concat(*[nd.flatten(\n",
    "            self.pool(conv(embeddings))) for conv in self.convs], dim=1)\n",
    "        # After applying the dropout method, use a fully connected layer to\n",
    "        # obtain the output\n",
    "        outputs = self.decoder(self.dropout(encoding))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('ratings_train.txt', sep='\\t').dropna(axis=0)\n",
    "train_data.head()\n",
    "train_corpus = train_data['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# co-occurrence matrix generate\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=10, ngram_range=(1,1))\n",
    "X = vectorizer.fit_transform(train_corpus)\n",
    "Xc = X.T * X             # co-occurrence matrix\n",
    "Xc.setdiag(0)            #대각성분을 0으로\n",
    "result = Xc.toarray()    # array로 변환\n",
    "dic = {}\n",
    "for idx1, word1 in enumerate(result):\n",
    "    tmpdic = {}\n",
    "    for idx2, word2 in enumerate(word1):\n",
    "        if word2 > 0:\n",
    "            tmpdic[idx2] = word2\n",
    "    dic[idx1] = tmpdic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 리스트 작성\n",
    "import operator\n",
    "vocab = sorted(vectorizer.vocabulary_.items(), key=operator.itemgetter(1))\n",
    "vocab = [word[0] for word in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/JonathanRaiman/glove.git\n",
      "  Cloning https://github.com/JonathanRaiman/glove.git to /tmp/pip-req-build-g1gwl6ry\n",
      "Requirement already satisfied: cython in /home/chee/anaconda3/lib/python3.6/site-packages (from glove==1.0.1) (0.27.3)\n",
      "Requirement already satisfied: numpy in /home/chee/anaconda3/lib/python3.6/site-packages (from glove==1.0.1) (1.14.0)\n",
      "Building wheels for collected packages: glove\n",
      "  Running setup.py bdist_wheel for glove ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-o3smc2h6/wheels/e4/ea/7c/0e887c01470d73c6b0f3395891804fc2923caca44dd76cdedc\n",
      "Successfully built glove\n",
      "Installing collected packages: glove\n",
      "Successfully installed glove-1.0.1\n",
      "\u001b[33mYou are using pip version 18.0, however version 19.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/JonathanRaiman/glove.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, error 0.010\n",
      "epoch 1, error 0.008\n",
      "epoch 2, error 0.006\n",
      "epoch 3, error 0.006\n",
      "epoch 4, error 0.006\n",
      "epoch 5, error 0.005\n",
      "epoch 6, error 0.005\n",
      "epoch 7, error 0.005\n",
      "epoch 8, error 0.005\n",
      "epoch 9, error 0.005\n",
      "epoch 10, error 0.005\n",
      "epoch 11, error 0.005\n",
      "epoch 12, error 0.004\n",
      "epoch 13, error 0.004\n",
      "epoch 14, error 0.004\n",
      "epoch 15, error 0.004\n",
      "epoch 16, error 0.004\n",
      "epoch 17, error 0.004\n",
      "epoch 18, error 0.004\n",
      "epoch 19, error 0.004\n",
      "epoch 20, error 0.004\n",
      "epoch 21, error 0.003\n",
      "epoch 22, error 0.003\n",
      "epoch 23, error 0.003\n",
      "epoch 24, error 0.003\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "import glove\n",
    "model = glove.Glove(dic, d=100, alpha=0.75, x_max=100.0)\n",
    "for epoch in range(25):\n",
    "    err = model.train(batch_size=200, workers=4)\n",
    "    print(\"epoch %d, error %.3f\" % (epoch, err), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<glove.glove.Glove at 0x7f31615e5400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model = model\n",
    "embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11940"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11940, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.ContextW"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
